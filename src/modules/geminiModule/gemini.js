const { GoogleGenerativeAI } = require("@google/generative-ai");
const fs = require("fs");
const path = require("path");
const logger = require("../../utils/logger");
const config = require(path.join(__dirname, "../../config/options.json"));

require("dotenv").config();
const genAI = new GoogleGenerativeAI(process.env.GEMINI_APIKEY);

const historyFilePath = path.join(__dirname, "data", "chatHistory.json");

async function generateAIContent(client, from, info, expirationMessage, sender, userName, text) {

    try {
    const historyDir = path.dirname(historyFilePath);
    if (!fs.existsSync(historyDir)) {
        fs.mkdirSync(historyDir, { recursive: true });
    }

    if (!fs.existsSync(historyFilePath)) {
        fs.writeFileSync(historyFilePath, JSON.stringify({}, null, 2));
    }
} catch (error) {
    logger.error("[ GEMINI MODEL ] Erro ao garantir exist√™ncia do hist√≥rico:", error);
}


    try {

        if (text.trim() === "" || text.trim() === "--hp") {
           await client.sendMessage(from, { react: { text: '‚ö†Ô∏è', key: info.key } });
        await client.sendMessage(from, { text: `*‚ö†Ô∏è Como usar o comando corretamente:*\n\n_Para interagir com a IA, voc√™ precisa fornecer um texto ap√≥s o comando._\n\n_*Exemplo:*_\n‚úÖ \`.cat bom dia\`\n\n_Isso iniciar√° ou continuar√° uma conversa com a IA, que mant√©m um hist√≥rico de at√© *72 horas* para lembrar o contexto._\n\nüîπ Personaliza√ß√£o:\n\`--ps [instru√ß√£o]\` ‚Üí Define um comportamento espec√≠fico para a IA.\n\n_*Exemplo:*_\n‚úÖ \`--ps Responda como um pirata.\`\n\n\`--lp\` ‚Üí Apaga todo o hist√≥rico da conversa.\n\nüîπ An√°lises e Relat√≥rios:\n\`--me\` ‚Üí Apresenta an√°lises individualizadas do usu√°rio que est√° interagindo, como perfil de uso (n√∫mero de intera√ß√µes, dia e hor√°rio preferidos), padr√µes de comunica√ß√£o, tempo m√©dio de resposta, sess√µes e outros dados extra√≠dos do hist√≥rico do usu√°rio.\n\n\`--all\` ‚Üí Gera um relat√≥rio global agregando dados de todos os usu√°rios, fornecendo m√©tricas como o total de intera√ß√µes, usu√°rios ativos, distribui√ß√£o de mensagens por tipo, padr√µes de atividade (dias e horas de pico) e outros insights sobre a base completa de hist√≥ricos.\n\nSe precisar de ajuda, acione o owner! üöÄ`}, { quoted: info, ephemeralExpiration: expirationMessage });
 return;
        }
    } catch (err) {
        logger.error("[ GEMINI MODEL ] Erro na verifica√ß√£o do comando inv√°lido:", err);
        return;
    }

    try {
        if (text.trim() === "--me") {
            let data = JSON.parse(fs.readFileSync(historyFilePath, "utf8"));
            let userData = data[sender] || { history: [], systemInstruction: "N√£o definida" };
            let history = userData.history;
            const totalMessages = history.length;

            // 1. Perfil de Uso
            const userNameDisplay = userName || "Desconhecido";
            const frequency = totalMessages;
            let dayCount = {};
            let hourCount = {};
            history.filter(msg => msg.role === "user").forEach(msg => {
                let d = new Date(msg.timestamp);
                let day = d.toLocaleDateString("pt-BR", { weekday: 'long' });
                let hour = d.getHours();
                dayCount[day] = (dayCount[day] || 0) + 1;
                hourCount[hour] = (hourCount[hour] || 0) + 1;
            });
            const favoriteDay = Object.entries(dayCount).sort((a, b) => b[1] - a[1])[0] || ["Nenhum", 0];
            const favoriteHour = Object.entries(hourCount).sort((a, b) => b[1] - a[1])[0] || ["Nenhum", 0];

            // 2. Padr√µes de Comunica√ß√£o
            let userMessages = history.filter(msg => msg.role === "user");
            let totalLength = userMessages.reduce((acc, msg) => {
                let len = msg.parts.reduce((sum, part) => sum + part.text.length, 0);
                return acc + len;
            }, 0);
            let avgLength = userMessages.length > 0 ? (totalLength / userMessages.length).toFixed(2) : "0";
            // Conte mensagens possivelmente aleat√≥rias (ex.: com menos de 3 palavras)
            let randomMessagesCount = userMessages.filter(msg => {
                let textContent = msg.parts.map(p => p.text).join(" ").trim();
                return textContent.split(/\s+/).length < 3;
            }).length;
            // Quantidade m√°xima de mensagens consecutivas do usu√°rio antes de uma resposta do bot
            let maxConsecutive = 0, currentConsecutive = 0;
            history.forEach(msg => {
                if (msg.role === "user") {
                    currentConsecutive++;
                } else if (msg.role === "model") {
                    if (currentConsecutive > maxConsecutive) { maxConsecutive = currentConsecutive; }
                    currentConsecutive = 0;
                }
            });
            if (currentConsecutive > maxConsecutive) { maxConsecutive = currentConsecutive; }

            // 3. Reten√ß√£o e Lealdade
            const sortedHistory = [...history].sort((a, b) => a.timestamp - b.timestamp);
            const firstInteraction = sortedHistory[0] ? new Date(sortedHistory[0].timestamp).toLocaleString("pt-BR") : "N/A";
            const lastInteraction = sortedHistory[sortedHistory.length - 1] ? new Date(sortedHistory[sortedHistory.length - 1].timestamp).toLocaleString("pt-BR") : "N/A";
            // Definir sess√µes: considere um intervalo de 1 hora entre intera√ß√µes para iniciar uma nova sess√£o
            let sessions = 0;
            let sessionStart = null;
            sortedHistory.forEach(msg => {
                if (!sessionStart) {
                    sessionStart = msg.timestamp;
                    sessions++;
                } else {
                    if (msg.timestamp - sessionStart >= 3600000) {
                        sessions++;
                        sessionStart = msg.timestamp;
                    }
                }
            });
            // Tend√™ncia de engajamento: compare intera√ß√µes do usu√°rio na primeira e na segunda metade
            const midIndex = Math.floor(sortedHistory.length / 2);
            const firstHalfCount = sortedHistory.slice(0, midIndex).filter(msg => msg.role === "user").length;
            const secondHalfCount = sortedHistory.slice(midIndex).filter(msg => msg.role === "user").length;
            const engagementTrend = secondHalfCount > firstHalfCount ? "Mais engajado recentemente" : (secondHalfCount < firstHalfCount ? "Menos engajado recentemente" : "Sem varia√ß√£o");

            // 4. Novos M√©tricos
            // Tempo m√©dio de resposta do bot
            let responseTimes = [];
            for (let i = 0; i < history.length - 1; i++) {
                if (history[i].role === "user" && history[i + 1].role === "model") {
                    responseTimes.push(history[i + 1].timestamp - history[i].timestamp);
                }
            }
            const avgResponseTime = responseTimes.length > 0 ? (responseTimes.reduce((a, b) => a + b, 0) / responseTimes.length / 1000).toFixed(2) + " seg" : "N/A";

            // Detec√ß√£o de mensagens repetidas
            let repeatedMessages = 0;
            for (let i = 1; i < history.length; i++) {
                if (history[i].role === "user" && history[i - 1].role === "user" &&
                    history[i].parts[0].text.trim() === history[i - 1].parts[0].text.trim()) {
                    repeatedMessages++;
                }
            }

            // Detec√ß√£o de emojis nas mensagens do usu√°rio
            let emojiRegex = /[\u{1F600}-\u{1F64F}]/gu;
            let totalEmojis = 0;
            userMessages.forEach(msg => {
                const count = (msg.parts.map(p => (p.text.match(emojiRegex) || [])).flat()).length;
                totalEmojis += count;
            });

            // Per√≠odo de Inatividade: gap m√©dio entre mensagens do usu√°rio
            let userTimestamps = userMessages.map(msg => msg.timestamp).sort((a, b) => a - b);
            let gaps = [];
            for (let i = 1; i < userTimestamps.length; i++) {
                gaps.push(userTimestamps[i] - userTimestamps[i - 1]);
            }
            // Convertendo de milissegundos para horas
            const avgInactivity = gaps.length > 0 ? (gaps.reduce((a, b) => a + b, 0) / gaps.length / 3600000).toFixed(2) + " horas" : "N/A";

            // Crescimento de Intera√ß√µes: compara√ß√£o entre o primeiro e o √∫ltimo dia
            let interactionsByDay = {};
            userMessages.forEach(msg => {
                const day = new Date(msg.timestamp).toLocaleDateString("pt-BR");
                interactionsByDay[day] = (interactionsByDay[day] || 0) + 1;
            });
            const days = Object.keys(interactionsByDay).sort();
            let growth = "N/A";
            if (days.length >= 2) {
                const firstDayCount = interactionsByDay[days[0]];
                const lastDayCount = interactionsByDay[days[days.length - 1]];
                growth = firstDayCount > 0 ? (((lastDayCount - firstDayCount) / firstDayCount) * 100).toFixed(2) + "%" : "N/A";
            }

            // Usu√°rio Ativo vs. Inativo
            const userStatus = frequency >= 10 ? "Ativo" : "Inativo";

            // Mensagens Curtas vs. Longas: com base na contagem de palavras
            let shortCount = 0, longCount = 0;
            userMessages.forEach(msg => {
                const wordCount = msg.parts.map(p => p.text).join(" ").trim().split(/\s+/).length;
                if (wordCount < 5) shortCount++;
                else longCount++;
            });

           const analyticsMsg =
                `üìä *Analytics do Usu√°rio:*\n\n` +
                `*1. Perfil de Uso:* \n` +
                `- Nome: ${userNameDisplay}\n` +
                `- Total de intera√ß√µes: ${frequency}\n` +
                `- Dia preferido: ${favoriteDay[0]} üìÖ (${favoriteDay[1]} msgs)\n` +
                `- Hor√°rio preferido: ${favoriteHour[0]}h (${favoriteHour[1]} msgs)\n\n` +
                `*2. Padr√µes de Comunica√ß√£o:*\n` +
                `- Comprimento m√©dio das mensagens: ${avgLength} caracteres\n` +
                `- Mensagens curtas/aleat√≥rias: ${randomMessagesCount}\n` +
                `- M√°ximo de mensagens consecutivas: ${maxConsecutive}\n\n` +
                `*3. Reten√ß√£o e Lealdade:*\n` +
                `- Primeira intera√ß√£o: ${firstInteraction}\n` +
                `- √öltima intera√ß√£o: ${lastInteraction} \n` +
                `- Sess√µes detectadas: ${sessions}\n` +
                `- Tend√™ncia de engajamento: ${engagementTrend}\n\n` +
                `*4. Novos M√©tricos:* \n` +
                `- Tempo m√©dio de resposta do bot: ${avgResponseTime}\n` +
                `- Repeti√ß√£o de mensagens consecutivas: ${repeatedMessages}\n` +
                `- Total de emojis detectados: ${totalEmojis}\n` +
                `- Per√≠odo m√©dio de inatividade: ${avgInactivity}\n` +
                `- Crescimento de intera√ß√µes (primeiro vs √∫ltimo dia): ${growth}\n` +
                `- Status do usu√°rio: ${userStatus}\n` +
                `- Mensagens curtas: ${shortCount} vs. Mensagens longas: ${longCount}\n\n` +
                `- Instru√ß√£o do sistema: ${userData.systemInstruction}`;


            await client.sendMessage(from, { react: { text: 'üìä', key: info.key } });
            await client.sendMessage(from, { text: analyticsMsg }, { quoted: info, ephemeralExpiration: expirationMessage });
            return;
        }
    } catch (error) {
        logger.error("[ GEMINI MODEL ] Erro ao processar os analytics do usu√°rio:", error);
        await client.sendMessage(from, { react: { text: '‚ÄºÔ∏è', key: info.key } });
        await client.sendMessage(from, { text: "*‚ÑπÔ∏è Ocorreu um erro ao processar os analytics do usu√°rio. Tente novamente posteriormente.*" }, { quoted: info, ephemeralExpiration: expirationMessage });
        return;
    }

    try {
        if (text.trim() === "--lp") {
            let data = {};

            if (fs.existsSync(historyFilePath)) {
                try {
                    const fileContent = fs.readFileSync(historyFilePath, "utf8");
                    data = fileContent ? JSON.parse(fileContent) : {};
                } catch (jsonErr) {
                    throw new Error("Falha ao ler o hist√≥rico: " + jsonErr);
                }
            }
            
            if (data && data[sender]) {

                delete data[sender];
                logger.info("[ GEMINI MODEL ] Excluindo hist√≥rico do usu√°rio...");

                try {
                    fs.writeFileSync(historyFilePath, JSON.stringify(data, null, 2));

                    await client.sendMessage(from, { react: { text: 'üóëÔ∏è', key: info.key } });
                    await client.sendMessage(from, { text: "_*üóëÔ∏è O hist√≥rico foi removido com sucesso! üöÄüòä*_" }, { quoted: info, ephemeralExpiration: expirationMessage });

                } catch (writeErr) {
                    throw new Error("Falha ao salvar as altera√ß√µes: " + writeErr);
                }

            } else {
                await client.sendMessage(from, { react: { text: '‚ùì', key: info.key }});
                await client.sendMessage(from, { text: "_*‚ùì N√£o h√° registro de hist√≥rico para o referido a ser exclu√≠do. ‚ÑπÔ∏è*_" }, { quoted: info, ephemeralExpiration: expirationMessage });
            }
            return;
        }
    } catch (error) {
        logger.error("[ GEMINI MODEL ] Erro ao processar exclus√£o de hist√≥rico:", error);

        await client.sendMessage(from, { react: { text: '‚ÄºÔ∏è', key: info.key }});
        await client.sendMessage(from, { text: "*‚ÑπÔ∏è Ocorreu um erro ao tentar excluir o hist√≥rico do usu√°rio. Por favor, tente novamente posteriormente.*" }, { quoted: info, ephemeralExpiration: expirationMessage });
        await client.sendMessage(config.owner.number, { text: `*Erro ao excluir hist√≥rico do usu√°rio:*\n\`\`\`${JSON.stringify(error, null,2)}\`\`\`` }, { quoted: info, ephemeralExpiration: expirationMessage });
        return;
    }

    try {
        if (text.startsWith("--ps ")) {

            const instructionText = text.slice(5);
            let data = {};

            if (fs.existsSync(historyFilePath)) {
                data = JSON.parse(fs.readFileSync(historyFilePath, "utf8"));
            }

            let userHistory = [];
            if (data[sender]) {
                userHistory = data[sender].history || [];
            }

            data[sender] = { history: userHistory, systemInstruction: instructionText };

            logger.info("[ GEMINI MODEL ] atualizando instru√ß√£o do sistema...");

            fs.writeFileSync(historyFilePath, JSON.stringify(data, null, 2));
            await client.sendMessage(from, { react: { text: '‚öôÔ∏è', key: info.key } });
            await client.sendMessage(from, { text: "_*üîÑ Instru√ß√£o do sistema para a personalidade da IA foi  atualizada com sucesso!*_" }, { quoted: info, ephemeralExpiration: expirationMessage });
            return;
        }
    } catch (error) {
        logger.error("[ GEMINI MODEL ] Erro ao atualizar instru√ß√£o do sistema:", error);
        await client.sendMessage(from, { react: { text: '‚ÄºÔ∏è', key: info.key } });
        client.sendMessage(from, { text: "*‚ÑπÔ∏è Ocorreu um erro ao tentar atualizar a instru√ß√£o do sistema. Por favor, tente novamente posteriormente.*" }, { quoted: info, ephemeralExpiration: expirationMessage });
        client.sendMessage(config.owner.number, { text: `*Erro ao atualizar a instru√ß√£o do sistema:*\n\`\`\`${JSON.stringify(error, null,2)}\`\`\`` }, { quoted: info, ephemeralExpiration: expirationMessage });
        return;
    }

    try {
        if (text.trim() === "--all") {
            let data = {};
            if (fs.existsSync(historyFilePath)) {
                data = JSON.parse(fs.readFileSync(historyFilePath, "utf8"));
            }
            // Vari√°veis agregadas
            let totalInteractions = 0;
            let totalUsers = 0;
            let activeUsers7 = 0;
            let activeUsers30 = 0;
            const now = Date.now();
            const oneDay = 24 * 3600000;
            const sevenDays = 7 * oneDay;
            const thirtyDays = 30 * oneDay;
            let dayCountGlobal = {};
            let hourCountGlobal = {};
            let randomGlobal = 0;
            let responseTimesGlobal = [];
            let totalEmojisGlobal = 0;
            let emojiFreq = {};
            let sessionsTotal = 0;
            let sessionLengths = [];
            let inactivityGaps = [];
            let userAvgReturnIntervals = [];
            // Distribui√ß√£o de tamanho de mensagens
            let shortMsg = 0, mediumMsg = 0, longMsg = 0;
            // Contagem para respostas r√°pidas (<2 seg)
            let quickResponses = 0;
            // Contador para novos vs. experientes (novo: <=3 intera√ß√µes)
            let newUsers = 0, experiencedUsers = 0;
            
            for (const sender in data) {
                totalUsers++;
                const userData = data[sender];
                const history = userData.history || [];
                totalInteractions += history.length;
                if (history.length > 0) {
                    let lastMsgTs = history[history.length - 1].timestamp;
                    if ((now - lastMsgTs) <= sevenDays) { activeUsers7++; }
                    if ((now - lastMsgTs) <= thirtyDays) { activeUsers30++; }
                    if (history.length <= 3) { newUsers++; } else { experiencedUsers++; }
                }
                const sortedHistory = [...history].sort((a, b) => a.timestamp - b.timestamp);
                for (let i = 0; i < sortedHistory.length; i++) {
                    const msg = sortedHistory[i];
                    const d = new Date(msg.timestamp);
                    let dayName = d.toLocaleDateString("pt-BR", { weekday: "long" });
                    dayCountGlobal[dayName] = (dayCountGlobal[dayName] || 0) + 1;
                    let hour = d.getHours();
                    hourCountGlobal[hour] = (hourCountGlobal[hour] || 0) + 1;
                    const textContent = msg.parts.map(p => p.text).join(" ").trim();
                    const words = textContent.split(/\s+/);
                    if (words.length < 3) {
                        randomGlobal++;
                    }
                    // Distribui√ß√£o de tamanho de mensagens
                    const wordCount = words.length;
                    if (wordCount < 5) {
                        shortMsg++;
                    } else if(wordCount <=15) {
                        mediumMsg++;
                    } else {
                        longMsg++;
                    }
                    let emojiRegex = /[\u{1F600}-\u{1F64F}]/gu;
                    const emojisFound = textContent.match(emojiRegex) || [];
                    totalEmojisGlobal += emojisFound.length;
                    emojisFound.forEach(e => { emojiFreq[e] = (emojiFreq[e] || 0) + 1; });
                    if (i > 0) {
                        inactivityGaps.push(msg.timestamp - sortedHistory[i-1].timestamp);
                    }
                }
                // Sess√µes (intervalo de 1 hora)
                let userSessions = 0;
                let sessionStart = null;
                let userReturnIntervals = [];
                for (let i = 0; i < sortedHistory.length; i++) {
                    const msg = sortedHistory[i];
                    if (!sessionStart) {
                        sessionStart = msg.timestamp;
                        userSessions++;
                    } else {
                        if (msg.timestamp - sessionStart >= 3600000) {
                            const sessionDuration = sortedHistory[i-1].timestamp - sessionStart;
                            sessionLengths.push(sessionDuration);
                            userReturnIntervals.push(msg.timestamp - sortedHistory[i-1].timestamp);
                            userSessions++;
                            sessionStart = msg.timestamp;
                        }
                    }
                }
                sessionsTotal += userSessions;
                if (userReturnIntervals.length > 0) {
                    const avgReturn = userReturnIntervals.reduce((a, b) => a + b, 0) / userReturnIntervals.length;
                    userAvgReturnIntervals.push(avgReturn);
                }
                for (let i = 0; i < sortedHistory.length - 1; i++) {
                    if (sortedHistory[i].role === "user" && sortedHistory[i+1].role === "model") {
                        let respTime = sortedHistory[i+1].timestamp - sortedHistory[i].timestamp;
                        responseTimesGlobal.push(respTime);
                        if (respTime/1000 < 2) { quickResponses++; }
                    }
                }
            }
            const avgResponseTimeGlobal = responseTimesGlobal.length > 0
                ? (responseTimesGlobal.reduce((a,b)=>a+b,0) / responseTimesGlobal.length / 1000).toFixed(2) + " seg"
                : "N/A";
            const quickResponseRate = responseTimesGlobal.length > 0 
                ? ((quickResponses / responseTimesGlobal.length) * 100).toFixed(2) + "%" 
                : "N/A";
            const avgInactivityGlobal = inactivityGaps.length > 0
                ? (inactivityGaps.reduce((a,b)=>a+b,0) / inactivityGaps.length / 3600000).toFixed(2) + " horas"
                : "N/A";
            const avgSessionsPerUser = totalUsers > 0 ? (sessionsTotal / totalUsers).toFixed(2) : "N/A";
            const avgSessionLength = sessionLengths.length > 0
                ? (sessionLengths.reduce((a,b)=>a+b,0)/sessionLengths.length/60000).toFixed(2) + " min"
                : "N/A";
            const avgReturnTime = userAvgReturnIntervals.length > 0
                ? (userAvgReturnIntervals.reduce((a,b)=>a+b,0)/userAvgReturnIntervals.length/3600000).toFixed(2) + " horas"
                : "N/A";
            const retentionRate = totalUsers > 0
                ? ((totalUsers - Object.values(data).filter(u => (u.history || []).length <= 1).length) / totalUsers * 100).toFixed(2) + "%"
                : "N/A";
            const avgInteractionsPerUser = totalUsers > 0 ? (totalInteractions / totalUsers).toFixed(2) : "N/A";
            const topEmojis = Object.entries(emojiFreq).sort((a,b)=>b[1]-a[1]).slice(0,3)
                .map(([emoji, count]) => `${emoji} (${count})`).join(", ") || "N/A";
            const topDay = Object.entries(dayCountGlobal).sort((a,b)=>b[1]-a[1])[0] || ["N/A", 0];
            const topHour = Object.entries(hourCountGlobal).sort((a,b)=>b[1]-a[1])[0] || ["N/A", 0];
            
            let analyticsAll =
`üìä *Analytics Global:*

1. An√°lise de Engajamento Global:
- Total de Intera√ß√µes: ${totalInteractions} mensagens
- Usu√°rios Ativos (√∫ltimos 7 dias): ${activeUsers7}
- Reten√ß√£o de Usu√°rios (mais de 1 intera√ß√£o): ${retentionRate}
- Padr√£o de Atividade: Dia mais ativo: ${topDay[0]} (${topDay[1]} msgs), Hora mais ativa: ${topHour[0]}h (${topHour[1]} msgs)

2. Distribui√ß√£o de Mensagens por Tipo:
- Distribui√ß√£o de Tamanho: Curtas: ${shortMsg}, M√©dias: ${mediumMsg}, Longas: ${longMsg}
- Mensagens Aleat√≥rias: ${randomGlobal}
- Uso de Emojis: ${totalEmojisGlobal} (Top 3: ${topEmojis})

3. An√°lise de Sess√µes e Tempo de Uso:
- Sess√µes por Usu√°rio (m√©dia): ${avgSessionsPerUser}
- Tempo M√©dio de Sess√£o por Usu√°rio: ${avgSessionLength}
- Tempo de Inatividade Global: ${avgInactivityGlobal}
- Tempo M√©dio Entre Intera√ß√µes: ${avgReturnTime}

4. An√°lise de Reten√ß√£o e Engajamento:
- Intera√ß√µes M√©dias por Usu√°rio: ${avgInteractionsPerUser}
- Taxa de Respostas R√°pidas (<2 seg): ${quickResponseRate}
- Usu√°rios Novos vs. Experientes: Novos: ${newUsers}, Experientes: ${experiencedUsers}
- Usu√°rios Ativos vs. Inativos (em 30 dias): Ativos: ${activeUsers30}, Inativos: ${totalUsers - activeUsers30}

5. Distribui√ß√£o de Intera√ß√µes:
- Intera√ß√µes por Hora/Dia da Semana: Verifique os picos em ${topHour[0]}h e ${topDay[0]}
- Distribui√ß√£o de Intera√ß√µes por M√™s: (N√£o implementado)

6. Crescimento de Usu√°rios Ativos:
- (M√©trica n√£o implementada)

7. Feedback e Qualidade de Resposta:
- Tempo M√©dio de Resposta: ${avgResponseTimeGlobal}
`;
            await client.sendMessage(from, { react: { text: 'üìä', key: info.key } });
            await client.sendMessage(from, { text: analyticsAll }, { quoted: info, ephemeralExpiration: expirationMessage });
            return;
        }
    } catch (error) {
        logger.error("[ GEMINI MODEL ] Erro ao processar analytics global:", error);
        await client.sendMessage(from, { react: { text: '‚ÄºÔ∏è', key: info.key } });
        await client.sendMessage(from, { text: "*‚ÑπÔ∏è Ocorreu um erro ao processar analytics global. Tente novamente posteriormente.*" }, { quoted: info, ephemeralExpiration: expirationMessage });
        return;
    }

    let history, systemInstruction;

    if (fs.existsSync(historyFilePath)) {

        const data = fs.readFileSync(historyFilePath, "utf8");
        const historyData = JSON.parse(data);

        logger.info("[ GEMINI MODEL ] carregando historico do usuario...");

        const userRecord = historyData[sender] || { history: [], systemInstruction: null };
        const prazo = 72 * 3600 * 1000;

        userRecord.history = userRecord.history.filter(record => (Date.now() - record.timestamp) < prazo);
        history = userRecord.history;
        systemInstruction = userRecord.systemInstruction;

    } else {
        history = [];
        systemInstruction = null;
    }

    systemInstruction = systemInstruction || "Responda sempre em portugu√™s de forma objetiva e direta, sem explica√ß√µes desnecess√°rias.";
    
    const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash", systemInstruction, });

    let now = Date.now();
    let formattedNow = new Date(now).toLocaleString("pt-BR", { timeZone: "America/Sao_Paulo" });
    
    history.push({ role: "user", name: userName, parts: [{ text: text }], timestamp: now, formattedTimestamp: formattedNow });
    
    const historyForAPI = history.map(({ timestamp, name, formattedTimestamp, ...msg }) => msg);
    const chat = model.startChat({ history: historyForAPI });
    let result;

    try {
        result = await chat.sendMessage([text]);
    } catch (error) {
        logger.error("[ GEMINI MODEL ] Erro ao gerar resposta do modelo:", error);
        await client.sendMessage(from, { react: { text: '‚ÄºÔ∏è', key: info.key } });
        await client.sendMessage(from, { text: "*‚ÑπÔ∏è Ocorreu um erro ao tentar gerar a resposta do modelo. Por favor, tente novamente posteriormente.*" }, { quoted: info, ephemeralExpiration: expirationMessage });  
        await client.sendMessage(config.owner.number, { text: `*Erro na gera√ß√£o do modelo: ${error.message}*` }, { quoted: info, ephemeralExpiration: expirationMessage });
        return;
    }

    logger.info("[ GEMINI MODEL ] gerando resposta do modelo...");

    now = Date.now();
    formattedNow = new Date(now).toLocaleString("pt-BR", { timeZone: "America/Sao_Paulo" });
    history.push({ role: "model", parts: [{ text: result.response.text() }], timestamp: now, formattedTimestamp: formattedNow });
    
    try {
        let dataToSave = {};
        if (fs.existsSync(historyFilePath)) {
            dataToSave = JSON.parse(fs.readFileSync(historyFilePath, "utf8"));
        }
    
        dataToSave[sender] = { history, systemInstruction };
        logger.info("[ GEMINI MODEL ] salvando historico do usuario...");
        fs.writeFileSync(historyFilePath, JSON.stringify(dataToSave, null, 2));
    } catch (err) {

        logger.error("[ GEMINI MODEL ] Erro ao salvar historico do usuario:", err);
        
        await client.sendMessage(from, { react: { text: '‚ÄºÔ∏è', key: info.key } });
        await client.sendMessage(from, { text: "*‚ÑπÔ∏è Ocorreu um erro ao tentar salvar o hist√≥rico do usu√°rio. Por favor, tente novamente posteriormente.*" }, { quoted: info, ephemeralExpiration: expirationMessage });
        await client.sendMessage(config.owner.number, { text: `*Error: ${err.message}*` }, { quoted: info, ephemeralExpiration: expirationMessage });
        return;
    }

    await client.sendMessage(from, { react: { text: 'üêà‚Äç‚¨õ', key: info.key }});
    await client.sendMessage(from, { text: result.response.text() }, { quoted: info, ephemeralExpiration: expirationMessage });
    return;
}

module.exports = { generateAIContent };

