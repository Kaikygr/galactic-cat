const { GoogleGenerativeAI } = require("@google/generative-ai");
const fs = require("fs");
const path = require("path");
const logger = require("../../utils/logger");
const config = require(path.join(__dirname, "../../config/options.json"));

require("dotenv").config();
const genAI = new GoogleGenerativeAI(process.env.GEMINI_APIKEY);

const historyFilePath = path.join(__dirname, "data", "chatHistory.json");

async function processAIContent(client, from, info, expirationMessage, sender, userName, text) {
  try {
    const historyDir = path.dirname(historyFilePath);
    if (!fs.existsSync(historyDir)) {
      fs.mkdirSync(historyDir, { recursive: true });
    }

    if (!fs.existsSync(historyFilePath)) {
      fs.writeFileSync(historyFilePath, JSON.stringify({}, null, 2));
    }
  } catch (error) {
    logger.error("[ GEMINI MODEL ] Erro ao garantir exist√™ncia do hist√≥rico:", error);
  }

  try {
    if (text.trim() === "" || text.trim() === "--hp") {
      await client.sendMessage(from, { react: { text: "‚ö†Ô∏è", key: info.key } });
      await client.sendMessage(
        from,
        {
          text: `*‚ö†Ô∏è Orienta√ß√µes para o uso correto do comando:*\n\n_Para interagir com a IA, √© necess√°rio fornecer um texto logo ap√≥s o comando._\n\n_*Exemplo:*_\n‚úÖ \`.cat bom dia\`\n\n_Essa a√ß√£o iniciar√° ou continuar√° uma conversa com a IA, que mant√©m o contexto por at√© *72 horas*._\n\nüîπ *Personaliza√ß√£o de comportamento:*\n\`.cat --ps [instru√ß√£o]\` ‚Üí Define um estilo ou comportamento espec√≠fico para a IA.\n\n_*Exemplo:*_\n‚úÖ \`.cat --ps Responda como um pirata.\`\n\nüßπ *Dica de efici√™ncia:*\nPara garantir uma personaliza√ß√£o mais precisa, siga esta ordem:\n1. ‚úÖ \`.cat --lp\` ‚Üí Limpa o hist√≥rico da conversa\n2. ‚úÖ \`.cat --ps [instru√ß√£o personalizada]\`\n\nüìö *Documenta√ß√£o completa do comando:*\nAcesse nossa Wiki para mais detalhes, exemplos e dicas de uso:\nüîó https://github.com/Kaikygr/galactic-cat/wiki/Comandos#cat\n\nCaso tenha d√∫vidas ou precise de suporte, entre em contato com o owner. üöÄ`,
        },
        { quoted: info, ephemeralExpiration: expirationMessage }
      );

      return;
    }
  } catch (erro) {
    logger.error("[ GEMINI MODEL ] Erro na verifica√ß√£o do comando inv√°lido:", erro);
    return;
  }

  try {
    if (text.trim() === "--lp") {
      let data = {};

      if (fs.existsSync(historyFilePath)) {
        try {
          const fileContent = fs.readFileSync(historyFilePath, "utf8");
          data = fileContent ? JSON.parse(fileContent) : {};
        } catch (jsonErr) {
          throw new Error("Falha ao ler o hist√≥rico: " + jsonErr);
        }
      }

      if (data && data[sender]) {
        delete data[sender];
        logger.info("[ GEMINI MODEL ] Excluindo hist√≥rico do usu√°rio...");

        try {
          fs.writeFileSync(historyFilePath, JSON.stringify(data, null, 2));

          await client.sendMessage(from, { react: { text: "üóëÔ∏è", key: info.key } });
          await client.sendMessage(
            from,
            {
              text: `_üóëÔ∏è *O hist√≥rico de conversa foi removido com sucesso!*_\n\n‚úÖ Para que as novas instru√ß√µes ou personaliza√ß√µes sejam aplicadas corretamente, por favor, utilize o comando novamente.\n\nSe precisar de ajuda, estou por aqui! üöÄüòä`,
            },
            { quoted: info, ephemeralExpiration: expirationMessage }
          );
        } catch (writeErr) {
          throw new Error("Falha ao salvar as altera√ß√µes: " + writeErr);
        }
      } else {
        await client.sendMessage(from, { react: { text: "‚ùì", key: info.key } });
        await client.sendMessage(
          from,
          {
            text: `_‚ùì *N√£o foi encontrado nenhum hist√≥rico associado que possa ser removido.*_\n\n‚ÑπÔ∏è Caso deseje iniciar uma nova conversa ou definir instru√ß√µes personalizadas, utilize os comandos apropriados. Estou √† disposi√ß√£o para ajudar!`,
          },
          { quoted: info, ephemeralExpiration: expirationMessage }
        );
      }
      return;
    }
  } catch (error) {
    logger.error("[ GEMINI MODEL ] Erro ao processar exclus√£o de hist√≥rico:", error);

    await client.sendMessage(from, { react: { text: "‚ÄºÔ∏è", key: info.key } });
    await client.sendMessage(
      from,
      {
        text: `*‚ÄºÔ∏è N√£o foi poss√≠vel excluir o hist√≥rico do usu√°rio no momento.*\n\n‚ÑπÔ∏è Por favor, tente novamente mais tarde. Caso o problema persista, entre em contato com o suporte.`,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    await client.sendMessage(
      config.owner.number,
      {
        text: `*‚ö†Ô∏è Erro ao tentar excluir o hist√≥rico de um usu√°rio:*\n\`\`\`${JSON.stringify(error, null, 2)}\`\`\``,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    return;
  }

  try {
    if (text.startsWith("--ps ")) {
      const instructionText = text.slice(5);
      let data = {};

      if (fs.existsSync(historyFilePath)) {
        data = JSON.parse(fs.readFileSync(historyFilePath, "utf8"));
      }

      let userHistory = [];
      if (data[sender]) {
        userHistory = data[sender].history || [];
      }

      data[sender] = { history: userHistory, systemInstruction: instructionText };

      logger.info("[ GEMINI MODEL ] atualizando instru√ß√£o do sistema...");

      fs.writeFileSync(historyFilePath, JSON.stringify(data, null, 2));
      await client.sendMessage(from, { react: { text: "‚öôÔ∏è", key: info.key } });
      await client.sendMessage(
        from,
        {
          text: `_‚öôÔ∏è *A instru√ß√£o do sistema referente √† personalidade da IA foi atualizada com sucesso!*_\n\n‚úÖ Utilize o comando novamente para que a nova configura√ß√£o seja aplicada corretamente.`,
        },
        { quoted: info, ephemeralExpiration: expirationMessage }
      );
      return;
    }
  } catch (error) {
    logger.error("[ GEMINI MODEL ] Erro ao atualizar instru√ß√£o do sistema:", error);
    await client.sendMessage(from, { react: { text: "‚ÄºÔ∏è", key: info.key } });
    await client.sendMessage(
      from,
      {
        text: `*‚ÄºÔ∏è Ocorreu um erro ao tentar atualizar a instru√ß√£o do sistema.*\n\n‚ÑπÔ∏è Por favor, tente novamente mais tarde. Se o problema persistir, entre em contato com o suporte.`,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    await client.sendMessage(
      config.owner.number,
      {
        text: `*‚ö†Ô∏è Erro ao atualizar a instru√ß√£o do sistema de um usu√°rio:*\n\`\`\`${JSON.stringify(error, null, 2)}\`\`\``,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    return;
  }

  let history, systemInstruction;

  if (fs.existsSync(historyFilePath)) {
    const data = fs.readFileSync(historyFilePath, "utf8");
    const historyData = JSON.parse(data);

    logger.info("[ GEMINI MODEL ] carregando historico do usuario...");

    const userRecord = historyData[sender] || { history: [], systemInstruction: null };
    const prazo = 72 * 3600 * 1000;

    userRecord.history = userRecord.history.filter(record => Date.now() - record.timestamp < prazo);
    history = userRecord.history;
    systemInstruction = userRecord.systemInstruction;
  } else {
    history = [];
    systemInstruction = null;
  }

  systemInstruction = systemInstruction || "Responda sempre em portugu√™s de forma objetiva e direta, sem explica√ß√µes desnecess√°rias.";

  const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash", systemInstruction });

  let now = Date.now();
  let formattedNow = new Date(now).toLocaleString("pt-BR", { timeZone: "America/Sao_Paulo" });

  history.push({ role: "user", name: userName, parts: [{ text: text }], timestamp: now, formattedTimestamp: formattedNow });

  const historyForAPI = history.map(({ timestamp, name, formattedTimestamp, ...msg }) => msg);
  const chat = model.startChat({ history: historyForAPI });
  let result;

  try {
    result = await chat.sendMessage([text]);
  } catch (error) {
    logger.error("[ GEMINI MODEL ] Erro ao gerar resposta do modelo:", error);
    await client.sendMessage(from, { react: { text: "‚ÄºÔ∏è", key: info.key } });
    await client.sendMessage(
      from,
      {
        text: `*‚ÄºÔ∏è Ocorreu um erro ao tentar gerar a resposta da IA.*\n\n‚ÑπÔ∏è Por gentileza, tente novamente em alguns instantes. Caso o problema continue, entre em contato com o suporte.`,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    await client.sendMessage(
      config.owner.number,
      {
        text: `*‚ö†Ô∏è Erro na gera√ß√£o de resposta do modelo para um usu√°rio:*\n\`\`\`${error.message}\`\`\``,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    return;
  }

  logger.info("[ GEMINI MODEL ] gerando resposta do modelo...");

  now = Date.now();
  formattedNow = new Date(now).toLocaleString("pt-BR", { timeZone: "America/Sao_Paulo" });
  history.push({ role: "model", parts: [{ text: result.response.text() }], timestamp: now, formattedTimestamp: formattedNow });

  try {
    let dataToSave = {};
    if (fs.existsSync(historyFilePath)) {
      dataToSave = JSON.parse(fs.readFileSync(historyFilePath, "utf8"));
    }

    dataToSave[sender] = { history, systemInstruction };
    logger.info("[ GEMINI MODEL ] salvando historico do usuario...");
    fs.writeFileSync(historyFilePath, JSON.stringify(dataToSave, null, 2));
  } catch (err) {
    logger.error("[ GEMINI MODEL ] Erro ao salvar historico do usuario:", err);

    await client.sendMessage(from, { react: { text: "‚ÄºÔ∏è", key: info.key } });
    await client.sendMessage(
      from,
      {
        text: `*‚ÄºÔ∏è Ocorreu um erro ao tentar salvar o hist√≥rico desta conversa.*\n\n‚ÑπÔ∏è Por favor, tente novamente mais tarde. Se o erro persistir, entre em contato com o suporte.`,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    await client.sendMessage(
      config.owner.number,
      {
        text: `*‚ö†Ô∏è Erro ao salvar o hist√≥rico do usu√°rio:*\n\`\`\`${err.message}\`\`\``,
      },
      { quoted: info, ephemeralExpiration: expirationMessage }
    );

    return;
  }

  await client.sendMessage(from, { react: { text: "üêà‚Äç‚¨õ", key: info.key } });
  await client.sendMessage(from, { text: result.response.text() }, { quoted: info, ephemeralExpiration: expirationMessage });
  return;
}

module.exports = { processAIContent };
